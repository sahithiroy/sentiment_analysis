# -*- coding: utf-8 -*-
"""sentiment analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-5WGycjchtxVcobmQNuNcpSzdVY5Mscz
"""

from textblob import TextBlob

a="The food at Radison good"
b="The food is very bad"
c=TextBlob(a)
d=TextBlob(b)
print(c.sentiment)
print(d.sentiment)

from sklearn.datasets import fetch_20newsgroups

text=fetch_20newsgroups()

import numpy as np

raw=text.data[:3]
raw

"""stage 1 Convert To lower text"""

clean_text=[]
def to_lower_case(data):
  for words in raw:
    clean_text.append(str.lower(words))

to_lower_case(raw)

clean_text

clean_text_2=[]
from nltk.tokenize import sent_tokenize,word_tokenize
import nltk
nltk.download('punkt')

sent_tok=[]
for sent in clean_text:
  sent=sent_tokenize(sent)
  sent_tok.append(sent)

#word tokenization
clean_text_2=[word_tokenize(i) for i in clean_text]

clean_text_2

import re
clean_text_3=[]
for word in clean_text_2:
  clean=[]
  for w in word:
    res=re.sub(r'[^\w\s]',"",w)
    if res!="":
      clean.append(res)
    clean_text_3.append(clean)

clean_text_3

#removing stopwords
import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords
clean_text_4=[]
for words in clean_text_3:
  w=[]
  for word in words:
    if not word in stopwords.words('english'):
      w.append(word)
    clean_text_4.append(w)

clean_text_4

#stemming
from nltk.stem.porter import PorterStemmer

port=PorterStemmer()

a=[port.stem(i) for i in ['reading','washing','wash','driving']]
a

clean_text_5=[]
for words in clean_text_4:
  w=[]
  for word in words:
    w.append(word)
  clean_text_5.append(w)

clean_text_5

from nltk.stem.wordnet import WordNetLemmatizer

wnet=WordNetLemmatizer()

import nltk
nltk.download('wordnet')
nltk.download('all')

lem=[]
for words in clean_text_4:
  w=[]
  for word in words:
    w.append(wnet.lemmatize(word))
     
  lem.append(w)

print(lem)

"""Navie Bayes """

import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from skelearn.model_selection import train_test_spilt

df=pd.read_csv('')